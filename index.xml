<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Trang Bui</title>
    <link>https://tqtbui.github.io/</link>
    <description>Recent content on Trang Bui</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; {year} Trang Bui</copyright>
    <lastBuildDate>Wed, 19 Nov 2025 00:00:00 -0500</lastBuildDate><atom:link href="https://tqtbui.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Meaningful Words</title>
      <link>https://tqtbui.github.io/miscs/appreciations/words/</link>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      
      <guid>https://tqtbui.github.io/miscs/appreciations/words/</guid>
      <description>Some of the many words that made my day and taught me so much. I am truly grateful for all the kindness that I have received over the the years. This has really kept me moving forward, motivated me to become a better person and reminded me to give back to the world.
  &amp;ldquo;I wish you good luck and happiness in your life. You have a long life in front of you.</description>
    </item>
    
    <item>
      <title>Courses</title>
      <link>https://tqtbui.github.io/teaching/courses/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tqtbui.github.io/teaching/courses/</guid>
      <description>University of Waterloo
 Analytic Methods for Business 2 Spring 2022. [Syllabus]. [Lecture Notes].  </description>
    </item>
    
    <item>
      <title>For publications</title>
      <link>https://tqtbui.github.io/projects/r/r-pub-package/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tqtbui.github.io/projects/r/r-pub-package/</guid>
      <description>These are the codes that I developed for my research and publications.
  Codes for Causal inference for the expected number of recurrent events in the presence of a terminal event.
  Codes for Genetic Algorithm-Based Bayesian Optimal Design for Network Experiments.
  Codes for the fourth Chapter of my Ph.D. thesis, Bayesian Optimal Designs for Experiments on Networks.
  </description>
    </item>
    
    <item>
      <title>My Books</title>
      <link>https://tqtbui.github.io/book/online-resources/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tqtbui.github.io/book/online-resources/</guid>
      <description>Online Resources
 Topics in Statistical Consulting - coauthored with SCSRU at University of Waterloo. A First Course in Statistics - written based on my lecture notes for AFM 113, Spring 2022 at University of Waterloo.  </description>
    </item>
    
    <item>
      <title>Papers</title>
      <link>https://tqtbui.github.io/research/papers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tqtbui.github.io/research/papers/</guid>
      <description>Experimental Design
  Genetic Algorithm-Based Bayesian Optimal Design for Network Experiments - with Steiner and Nathaniel T. Stevens. Technometrics (2025). pp 1-20. doi 10.1080/00401706.2025.2584500.
  General additive network effects model - with Stefan H. Steiner and Nathaniel T. Stevens. New England Journal of Statistics and Data Science (2023). pp 1-19, doi 10.51387/23-NEJSDS29.
 Featured in the “Design and Analysis of Experiments for Data Science” webinar by the New England Journal of Statistics in Data Science.</description>
    </item>
    
    <item>
      <title>Resources</title>
      <link>https://tqtbui.github.io/miscs/resources/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tqtbui.github.io/miscs/resources/</guid>
      <description>Useful resources:
  Seminar series: OCSI, NISS, ASA SLDS.
  Data: R datasets, Harvard Dataverse, UCI Datasets, Network Repository, SNAP Network Datasets, Kaggle.
  Applying for a faculty position in Statistics: blog posts by Dr. Ray Bai and Dr. Bingkai Wang.
  Growth as a faculty: NISS seminar.
  </description>
    </item>
    
    <item>
      <title>News</title>
      <link>https://tqtbui.github.io/miscs/featuring/</link>
      <pubDate>Sun, 17 Feb 2013 00:00:00 -0500</pubDate>
      
      <guid>https://tqtbui.github.io/miscs/featuring/</guid>
      <description>Some news and online articles featuring me.
2017-2025
 2025/08: I received the myHub Travel Award, 2025. 2025/06: I received the Student Travel Support for the Quality and Productivity Research Conference, 2025. 2024/06/05: I obtained the Honorable Mention in the Student Research Oral Presentation Competition in Data Science and Analytics at the SSC Annual Meeting, 2024. 2024/04/10: I received the Distinguished Service Award for the UWaterloo&amp;rsquo;s Women in Mathematics Directed Reading Program.</description>
    </item>
    
    <item>
      <title>Academic Appreciation</title>
      <link>https://tqtbui.github.io/miscs/appreciations/academic/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tqtbui.github.io/miscs/appreciations/academic/</guid>
      <description>I would like to continually remind myself of how fortunate I am in my academic journey. While I cannot name each individual, I extend my sincere gratitude to the Professors and Researchers I have worked with or met. Their valuable opportunities, generous support, and thoughtful advice have shaped both my work and my career.</description>
    </item>
    
    <item>
      <title>My Recommendations</title>
      <link>https://tqtbui.github.io/book/book-recommendation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tqtbui.github.io/book/book-recommendation/</guid>
      <description>Van der Vaart, A. W. (2012). Asymptotic statistics. Cambridge University Press. Tsiatis, A. A. (2006). Semiparametric theory and missing data (Vol. 4). New York: Springer. Howell, D. C. (2012). Statistical methods for psychology. Cengage Learning. Douglas, C. M. (2019). Design and analysis of experiments. John Wiley &amp;amp; Sons Ltd. McCulloch, C. E., &amp;amp; Searle, S. R. (2008). Generalized, linear, and mixed models. John Wiley &amp;amp; Sons. Seber, G. A., &amp;amp; Wild, C.</description>
    </item>
    
    <item>
      <title>Talks</title>
      <link>https://tqtbui.github.io/research/talks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tqtbui.github.io/research/talks/</guid>
      <description>Outperformance Score: A Universal Standardization for Confusion Matrix-Based Classification Performance Metrics: The Thirteenth Annual Conference of the Upstate Chapters of the American Statistical Association (2025); Quality and Productivity Research Conference (2025); Data Science Research Group at Rochester Institute of Technology (2025); Ploutos AI Community Livestream (2025).
  Optimal Bayesian Designs for Network A/B Testing: Joint Research Conference on Statistics in Quality, Industry, and Technology (2024); ASA/IMS Spring Research Conference (2025).</description>
    </item>
    
    <item>
      <title>Tutorial packages</title>
      <link>https://tqtbui.github.io/projects/r/r-tutorial-package/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tqtbui.github.io/projects/r/r-tutorial-package/</guid>
      <description>Below are R packages that I developed for the sole purpose of studying. Thus they will not be maintained. The codes are well-commented for step-by-step understanding of algorithms. These can be used for teaching or self-studying.
  varngc: Penalized regressions on Vector Autoregressive models. The loss functions used include penalized least square and penalized log-likelihood. The penalty include lasso and group lasso. This package is parallelizable.
  t.regression: Contains regression models from UWaterloo&amp;rsquo;s STAT844 course instructed by Professor Liang Kun, adapted from the lecture notes of Professor Wayne Oldford.</description>
    </item>
    
    <item>
      <title>Students</title>
      <link>https://tqtbui.github.io/research/students/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tqtbui.github.io/research/students/</guid>
      <description>Undergraduates
  Sanika Poojary. UWaterloo&amp;rsquo;s WiM DRP (2024). Project: Introduction to Explanable AI → Master of Data Science and Artificial Intelligence at University of Waterloo.
  Jamiee Yeung. UWaterloo&amp;rsquo;s WiM DRP (2023, 2024). Projects: Visualizing and Analyzing Spatially Correlated Data, Introduction to Explanable AI → Analyst at Evercore.
  Sagun Malwatkar. UWaterloo&amp;rsquo;s WiM DRP (2023). Project: Asymptotics for Linear Regression → Software Development Engineer at Amazon.
  </description>
    </item>
    
    <item>
      <title>Advice for Ph.D. students</title>
      <link>https://tqtbui.github.io/miscs/blogs/phd-exp/</link>
      <pubDate>Mon, 04 Mar 2024 00:00:00 -0500</pubDate>
      
      <guid>https://tqtbui.github.io/miscs/blogs/phd-exp/</guid>
      <description>I recently submitted my thesis, which marks the end of my long and hard Ph.D. journey. Reflecting on my bumpy road, there are something I wish I knew. I think it will be beneficial to share my thoughts, in case they can be helpful to someone.
  The most important keys for success in any field is persistence and consistency. It will be very helpful to have a good working routine, diet and exercise.</description>
    </item>
    
    <item>
      <title>Why is Deep Learning good?</title>
      <link>https://tqtbui.github.io/miscs/blogs/why-dl/</link>
      <pubDate>Thu, 03 Dec 2020 00:00:00 -0500</pubDate>
      
      <guid>https://tqtbui.github.io/miscs/blogs/why-dl/</guid>
      <description>Thanks to the David Sprott&amp;rsquo;s Distinguished Lecture by Professor Trevor Hastie and the question raised by Professor Ali Ghodsi in the Q&amp;amp;A session today, I realized several things about Deep Learning. I think there are three main reasons why they are so good:
 Deep Learning is like a stack of simpler models. Simple models, such as linear models, are ensembled together into a certain, probably hierarchical, structure. Thus, Deep Learning models usually contain many more parameters than other classical models.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://tqtbui.github.io/home/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tqtbui.github.io/home/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Teaching Assistantships</title>
      <link>https://tqtbui.github.io/teaching/ta/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://tqtbui.github.io/teaching/ta/</guid>
      <description>During my graduate study at University of Waterloo, I work as a teaching assistant for many courses. Below is the list of courses that I have assisted.
 ACTSC 231 Introductory Financial Mathematics Spring 2018. STAT 202 Introductory Statistics for Scientists Fall 2017. STAT 211 Introductory Statistics and Sampling for Accounting Winter 2019. STAT 230 Probability Fall 2018, Winter 2018. STAT 316 Introduction to Statistical Problem Solving by Computer Winter 2019.</description>
    </item>
    
  </channel>
</rss>
